
# Attention.Ai - Academic Research Paper Assistant üéì
This project is a fast, intuitive tool for researchers and students to search for academic papers, get quick summaries, and receive targeted answers to their questions!




## Installation‚¨áÔ∏è
Neo4js for graph database
```bash
  !pip install Neo4js
  from neo4j import GraphDatabase
```
Transformers
```bash
  !pip install transformers
```

HuggingFaceü§ó

Login into your huggingface profile and generate token.
```bash
  !huggingface-cli login
```
Outlines
```bash
  !pip install outlines
```

The model, Ministral 8B is
Trained with a 128k context window with interleaved sliding-window attention
Trained on a large proportion of multilingual and code data
(So, better to run on Google Colab)



## DatabaseGeneration
The project utilizes the ArXiv API to retrieve data from millions of research papers based on the user‚Äôs prompt topic. This data is then structured into a Neo4j graph database, enabling fast, flexible retrieval. With nodes organized by key attributes like author, title, publication date, and more, the graph database allows users to easily explore relationships between papers and find relevant research insights effortlessly.




## Summarizer
In this setup, a quantized Ministral model generates responses based on user-selected papers,i.e User is asked the topic, After which all relevant papers are displayed by using a drop down key. The user can select a specific title to get the detailed summary along with the Github Repo link also (if available) and the actual paper link can also be accessed by clicking on 'Read More' which are processed by calling our LLM model.
## QnA
When a general question is requested, the system creates a prompt based on content, title along with the question by user for each paper, and the model generates an answer for this prompt. The answer is stored in a vector along with confidence scores.The user is presented with the answer based on highest-confidence score along with its source, plus an alternative option for comparison. This approach ensures users receive the most relevant information with confidence-based accuracy.
## Streamlit app
To run Streamlit app on colab, 
ensure these dependencies are installed or install them using

```bash
  !pip install streamlit pyngrok neo4j sentence-transformers
```
# Authenticate ngrok with your authtoken
This token is to be generated by logging in into https://dashboard.ngrok.com/ .

use this command to Authenticate in your cell
```bash
  !ngrok authtoken <YOUR TOKEN>
```
start the streamlit_app

once loaded, you can visit the ngrok host link to use the app.


## Colab Notebook
Since the model requires approximately 9GB RAM, therefore it is better to use google Colab

The model will take a few minutes to load :)

```bash
    
```
